{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l2_BUoGbMh3"
      },
      "source": [
        "# Project 2: LangChain RAG Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JELltxGoSCmM"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-pinecone langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DFxwLw4fUeRX"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pinecone_api_key = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YqyVCyx2Vn-W"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "index_name = \"langchain-rag-project\"\n",
        "\n",
        "pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "63bD6B1abo-S"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hOaVnzU0cUQm"
      },
      "outputs": [],
      "source": [
        "vector = embeddings.embed_query(\"We Are Building A Rag Text Based Output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG0UXi6Zcrac",
        "outputId": "29ebbbbb-7b90-4bb8-b001-3efaecb12f3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.02381775714457035,\n",
              " -0.014614936895668507,\n",
              " -0.05852246657013893,\n",
              " -0.012175202369689941,\n",
              " 0.015380159951746464]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VvNur75PD1wn"
      },
      "outputs": [],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qdLkEf2RFtsr"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZDs-ur-Fx-5",
        "outputId": "57f90059-f65c-4694-fb4e-1072bf07b1b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'tweet'}, page_content='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FWe2iWE1FX8b"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lYWHB-RGGwE",
        "outputId": "d65cfa3a-b820-431b-cb99-ce8014c09519"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCWLhwNuGkCP",
        "outputId": "22a081ab-0325-4b45-c5db-ba3e96cee518"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "UUID('88183d96-fe29-4fc0-bf87-fa9a2c9f9d4b')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from uuid import uuid4\n",
        "uuid4()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELW6S-t5GM9K",
        "outputId": "9d419940-4e44-4e05-fd16-f0f15ef6588d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['c07f9b53-df6f-4706-9ca8-2081befac1ed',\n",
              " 'a3cfd5cc-34c3-47a4-899c-842d3dc0d215',\n",
              " '29099c26-1392-4f0b-ab71-1361c06f3ed7',\n",
              " '6db34eca-28cd-485c-8ad6-b8ff16be0119',\n",
              " '1fad759f-ef3f-46db-8afe-3209ec0b8b64',\n",
              " 'cf0371dd-bf7a-41b2-917e-16012e346bb1',\n",
              " '952d291c-8aff-447d-93ee-f9cc49c514e6',\n",
              " '4abcbe39-34a6-40db-8aed-5a05c964225d',\n",
              " '199c37f8-7fc3-4d31-b86c-e1fb6fb56509',\n",
              " '98bac295-b186-461b-9609-628f87c35988']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "t6YjyAVXHtio"
      },
      "outputs": [],
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=10,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qSv3KmeNIkII"
      },
      "outputs": [],
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6uy-sO6sOEFY"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jdbBkrQ7I2wN"
      },
      "outputs": [],
      "source": [
        "def answer_to_user(query: str):\n",
        "\n",
        "    ## Vector Search\n",
        "    # results = vector_store.similarity_search(query, k=2)\n",
        "    vector_results = vector_store.similarity_search(query, k=2)\n",
        "    print(len(vector_results))\n",
        "\n",
        "    ## Todo - Pass To Model Vector Results + User Query\n",
        "    # final_answer = model(query, results)\n",
        "    final_answer = llm.invoke(f\"ANSWER THIS USER QUERY: {query}, Here are some references to asnwer {vector_results} \")\n",
        "\n",
        "    return final_answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZSHA-mBLcxV",
        "outputId": "6e95742d-6bdb-4122-a420-05bce60b41af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "answer = answer_to_user(\"LangChain provides abstractions to make working with LLMs easy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Xw9KOkagOvaI",
        "outputId": "5fb6c670-220f-4074-fe34-35ec52ef6f49"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Based on the provided documents, here\\'s what we can say about LangChain:\\n\\n*   **LangChain is used for building applications.** The second tweet mentions \"Building an exciting new project with LangChain,\" indicating its use in application development.\\n*   **LangChain is a framework.** The first tweet refers to \"LangGraph,\" which is described as a framework, and it\\'s mentioned in the context of \"agentic applications.\" This suggests that LangChain (or at least its related components like LangGraph) is a framework for building applications.\\n*   **LangChain can be used for building stateful, agentic applications.** The first tweet specifically mentions \"LangGraph\" as the best framework for this type of application. This implies that LangChain, through components like LangGraph, supports the development of applications that have state and act like agents.\\n\\n**In summary, based on these limited references, LangChain is a framework used for building applications, including stateful, agentic ones.**\\n\\nIt\\'s important to note that these are just two tweets and don\\'t provide a comprehensive overview of LangChain\\'s capabilities. However, they do support the initial statement that LangChain provides abstractions to make working with LLMs easier by providing a framework for building applications.\\n'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd2OOnRrbbP8"
      },
      "source": [
        "## The End..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
